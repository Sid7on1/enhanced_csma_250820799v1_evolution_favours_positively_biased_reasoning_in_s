{
  "agent_id": "coder1",
  "task_id": "task_6",
  "files": [
    {
      "name": "setup.py",
      "purpose": "Package installation setup",
      "priority": "low"
    }
  ],
  "project_info": {
    "project_name": "enhanced_cs.MA_2508.20799v1_Evolution_favours_positively_biased_reasoning_in_s",
    "project_type": "agent",
    "description": "Enhanced AI project based on cs.MA_2508.20799v1_Evolution-favours-positively-biased-reasoning-in-s with content analysis. Detected project type: agent (confidence score: 7 matches).",
    "key_algorithms": [
      "Hierarchy",
      "1Machine",
      "Same",
      "Each",
      "Population",
      "Adaptive",
      "Popular",
      "Dependent",
      "Belief",
      "Potential"
    ],
    "main_libraries": [
      "torch",
      "numpy",
      "pandas"
    ]
  },
  "paper_content": "PDF: cs.MA_2508.20799v1_Evolution-favours-positively-biased-reasoning-in-s.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\nEvolution favours positively biased reasoning\nin sequential interactions with high future\ngains\nMarco Saponara1,a,\u2217, Elias Fern\u00b4 andez Domingos1,2,b,\nJorge M. Pacheco3,4,c, Tom Lenaerts1,2,5,d\n1Machine Learning Group, ULB, Campus la Plaine, Brussels 105 0, Belgium\n2Arti\ufb01cial Intelligence Lab, VUB, Pleinlaan 9, Brussels 105 0, Belgium\n3INESC-ID, IST-Tagusparque, 2744-016 Porto Salvo, Portuga l\n4ATP-group, P-2744-016 Porto Salvo, Portugal\n5Center for Human-Compatible AI, UC Berkeley, 2121 Berkeley Way, Berkeley, CA 94720, USA\naORCID iD: 0009-0008-8092-6220bORCID iD: 0000-0002-4717-7984\ncORCID iD: 0000-0002-2579-8499dORCID iD: 0000-0003-3645-1455\n\u2217Corresponding author. Email: marco.saponara@ulb.be\nAbstract\nEmpirical evidence shows that human behaviour often deviat es\nfrom game-theoretical rationality. For instance, humans m ay hold\nunrealistic expectations about future outcomes. As the evo lutionary\nroots of such biases remain unclear, we investigate here how reason-\ning abilities and cognitive biases co-evolve using Evoluti onary Game\nTheory. In our model, individuals in a population deploy a va riety of\nunbiased and biased level\u2013 kreasoning strategies to anticipate others\u2019\nbehaviour in sequential interactions, represented by the I ncremental\nCentipede Game. Positively biased reasoning strategies ha ve a sys-\ntematic inference bias towards higher but uncertain reward s, while\nnegatively biasedstrategies re\ufb02ecttheoppositetendency . We\ufb01ndthat\nselection consistently favours positively biased reasoni ng, with ratio-\nnal behaviour even going extinct. This bias co-evolves with bounded\nrationality, as the reasoning depth remains limited in the p opulation.\n1arXiv:2508.20799v1  [cs.MA]  28 Aug 2025\n\n--- Page 2 ---\nInterestingly, positively biased agents may co-exist with non-reasoning\nagents, thus pointing to a novel equilibrium. Longer games f urther\npromote positively biased reasoning, as they can lead to hig her future\nrewards. The biased reasoning strategies proposed in this m odel may\nre\ufb02ect cognitive phenomena like wishful thinking and defen sive pes-\nsimism. This work therefore supports the claim that certain cognitive\nbiases, despite deviating from rational judgment, constit ute an adap-\ntive feature to better cope with social dilemmas. This is the early\nversion of a manuscript published in the Royal Society Inter-\nface journal. DOI: https://doi.org/10.1098/rsif.2025.0153\n1 Introduction\nA large body of experimental evidence has shown that humans can b ehave\ndi\ufb00erently from the self-interested rational decision makers hypo thesized by\ngame-theoretical models [1, 2, 3, 4, 5]. In fact, our decisions may n ot pro-\nduce outcomes that align with classical solution concepts such as th e Nash\nequilibrium [6]. Instead, they may contain biases, i.e., consistent devia tions\nfrom a reference \u2013 rational behaviour \u2013 deemed to be correct [7, 8 , 9]. Such\nbiases, on the one hand, in\ufb02uence strategic reasoning and, on the other hand,\nrender their evolutionary roots di\ufb03cult to explain [10].\nTrivers\u2019theory of self-deception [11,12]arguesthattheevolutionofcogni-\ntive biases stems from the adaptive advantages of deceiving onese lf to better\npersuade or deceive others, thereby reducing the cognitive cost associated\nwith dishonesty in social interactions. This capacity is closely related to the\nnotion of Theory of Mind (ToM) [13], which allows us to attribute mental\nstates such as beliefs, intentions, and desires to others [14]. In fa ct, this early\nprocess enabled the development of a crucial feature of human so cial cogni-\ntion that is usually de\ufb01ned as inter-subjectivity (i.e., an understanding of the\nintentionality of others), thus rendering social transgressions m ore likely to\nbe detected and punished.\nIn a recent publication [15], we proposed an evolutionary model to st udy\nthe conditions under which ToM may have evolved, \ufb01nding that interm ediate\nlevels of ToM, interpreted as recursive reasoning of the sort A thinks that B\nthinks that A thinks that B will do X [16, 13], co-evolve with an optimism\nbias regarding the expected behaviour of other individuals in the con text\nof mixed-motive interactions. This theoretical work also showed th at the\nexpectation of higher future rewards is essential for the appear ance of ToM,\n2\n\n--- Page 3 ---\nand that the behaviour generated by the surviving reasoning stra tegies aligns\nwell with previous experimental data [2].\nHere, we go beyond the work in [15] by exploring the evolutionary dy-\nnamics of biased and unbiased reasoning strategies using the frame work of\nEvolutionary Game Theory [17, 18, 19, 20]. Strategic reasoning is re pre-\nsented, as in [15], through the lens of level\u2013 ktheory [21, 22, 23], a popular\napproach to model bounded rationality [24] (i.e., the idea that people have\nlimited cognitive capacity and might follow a strategy which is not perfe ctly\nrational). In this framework, the degree of rationality, or sophistication , of\nan individual is represented by an integer k\u22650, where no reasoning ( k= 0)\ncorresponds to an individual acting on ingrained beliefs while higher va lues\ntranslate into a more sophisticated reasoning capacity.\nThe goal here is to investigate whether reasoning strategies with p artic-\nular properties may be favoured by evolution. In our evolutionary m odel,\ndescribed in section 4, individuals are equipped with reasoning strate gies\nwhose cognitive bias within the reasoning process is modulated by a no ise\nparameter \u03b5. Depending on the type of reasoning process, the parameter\n\u03b5perturbs the inferred action away from the deterministic best-re sponse at\neach reasoning step (see section 4 for details). As a result, the ou tcome of\nthe reasoning process of an agent may systematically deviate from what is\nexpected from their reasoning level k, basing their strategic choices on a\nsubjective interpretation of reality, possibly triggered by both ex ternal and\ninternal factors such as the temptation for higher future rewar ds, as well as\nthe anticipated behaviour of other individuals in the population.\nWe therefore relax the underlying assumption in [15], wherein every in -\ndividual shared the same reasoning process and made mistakes in th e same\nway. In this regard, our aim is to answer the following series of quest ions:\n1) Under which conditions is rational behaviour replaced by di\ufb00erent reason-\ning strategies;\n2) Whether cognitively biased forms of reasoning are preferred to unbiased\nforms (with biases representing di\ufb00erent types of systematic mist akes within\neach reasoning process); and\n3) Whether an evolutionary robust strategy emerges or whether multiple\nreasoning strategies may co-exist in the population.\nAs in [15], the current analysis is also performed within the context of the\nCentipede Game [25], a sequential game with complete and perfect inf orma-\n3\n\n--- Page 4 ---\ntion that involves two individuals1who take turns, over a total of Lsteps,\ndeciding between two actions ( T=Take,P=Pass) regarding the split of a\nresource. Player 1 (Player 2) can play Tat even (odd) steps. Playing Tat a\ngiven step means ending the gameandreceiving alarger share of the resource\nthan the co-player. Playing Pmeans letting the other player decide what to\ndo in the next step, unless the last decision node is reached, where P layer 2\nhas to decide between two di\ufb00erent splits (see Figure 1 for an examp le).\nThe payo\ufb00 structure of a Centipede Game is designed such that solv ing\nthe game via the game-theoretical method of backward induction le ads a\nrational self-interested individual to play Tat every opportunity. Hence,\nin the unique subgame-perfect Nash equilibrium (SPE), each player c hooses\nto end the game as early as possible2. Nevertheless, several studies have\nshown that this equilibrium strategy is rarely observed during behav ioural\nexperiments, especially when the resource to be shared grows with each step\nof the game [2, 28, 29]. Here we focus on the Incremental Centipede Game\n(ICG), where the resource starts at 0.5 and doubles at every ste p [2, 30].\nIn Figure 1, we visualize the extensive form and the payo\ufb00 structur e for the\ncase where L= 6.\nSeveral explanations have been proposed to bridge the gap betwe en the-\noretical and experimental results in the Centipede Game. Typically, they\ncan be categorized into two main groups, focusing either on insu\ufb03cie nt cog-\nnitive ability to perform backward induction reasoning [31, 32, 21, 2 2], or\non other-regarding motives that might interfere with self-interes ted decision\nmaking [33, 34, 35]. Here, we argue that the potential evolutionary advan-\ntage of certain cognitive biases might have interfered with the deve lopment\nof backward induction reasoning, as these deviations might have be en the\nresult of heuristics adapted to deal with the complexity of uncerta in environ-\nments [36, 37].\nOur contributions are threefold. First, we show that a reasoning s trat-\negy with a systematic inference bias towards higher but uncertain r ewards\nis favoured and becomes dominant under strong selection, wherea s rational\nbehaviour undergoes extinction. Individuals employing such a biased infer-\nence process think, at each step, that higher-payo\ufb00 outcomes a re more likely\nto occur compared to individuals using the analogous unbiased strat egy. In\n1For extensions to 3-player Centipede Games, see [26, 27].\n2Remarkably, all Nash equilibria in a Centipede Game require Player1 to e nd the game\nat the \ufb01rst step.\n4\n\n--- Page 5 ---\nthis sense, their reasoning process, if compared to the unbiased r easoning\ntype, systematically overestimates the probability that the ICG will end at\na later node. As a result, they tend (with some probability that depe nds\non the noise parameter \u03b5) to direct their decisions to stop the game at later\nsteps with respect to an unbiased level\u2013 kprocess, with no guarantee of ac-\ntually reaching them. Given these features, we label this reasoning strategy\nas apositively biased reasoning strategy, whereas its inverse (i.e., directing\ntheir decisions to stop the ICG at earlier steps with respect to the u nbiased\nreasoning type) is a negatively biased reasoning strategy.\nOursecondcontributionistoshowthatthesophisticationofeachin divid-\nual, i.e., the depth of their reasoning processes, remains limited, und erlining\nonce more that explicit costs are not required to observe the emer gence of\nbounded rationality [38, 15, 39]. Interestingly, we reveal the poss ibility of a\nco-existence between a myopic payo\ufb00-maximising strategy (i.e., end ing the\ngame in accordance with the personal highest payo\ufb00 without any re asoning\nabout the possible decision of the other player) and one level of pos itively\nbiased reasoning (i.e., an individual with k= 1 reasoning capacity whose\nmistakes in reasoning are biased towards higher future gains). This \ufb01nd-\ning is aligned with previous econometric analyses [2, 22], which assumed the\npresence of a minority of altruistic players to align with experimental data.\nYet we propose here that some individuals are driven by a desire to ob tain\nthemaximum payo\ufb00 inthegamerather thanby ahighpro-socialorien tation,\nthereby not relying on explanations related to other-regarding mo tives.\nFinally, we identify that the length of the ICG, de\ufb01ned by the parame ter\nL, is instrumental for the evolutionary success of positively biased r easoning,\nas longer exchanges lead to exponentially higher rewards. Speci\ufb01ca lly, higher\nvalues of Lamplify the range of cognitive noise \u03b5for which positively biased\nreasoning is the most frequent strategy in the population. We obse rve never-\ntheless a limit to the window of noise values wherein this reasoning stra tegy\nis successful, as excessive cognitive noise renders any type of rea soning evo-\nlutionary detrimental.\nThrough these contributions, the present work further explains the emer-\ngence of the non-rational behaviour that is frequently observed in the ex-\nperimental literature involving this sequential dilemma [34] as well as others\n[40,41]. Ourtheoreticalmodel, appliedinthecontext ofreciprocal exchanges\nof resources, thus corroborates the idea that certain cognitive biases, despite\nleading to systematic deviations from a rational judgment, can con stitute an\nadaptive feature to successfully interact with our peers in this kind of social\n5\n\n--- Page 6 ---\ndilemmas.\n2 Results and Discussion\nTounderstandwhichformofreasoning, eitherunbiasedorbiased, ispreferred\nby evolution, we examine the evolutionary dynamics of \ufb01ve types of r eason-\ning. We consider two basic types, namely the rational strategy of s topping\nthe game as early as possible (i.e., the sub-game perfect equilibrium st rategy,\norSPE), and the myopic payo\ufb00-maximizers who ignore the possible choices\nof the other player and stop the game at the node which maximises th eir\npersonal reward (i.e., no-reasoning, NR, or equivalently k= 0). In our case,\nthe latter strategy corresponds to always playing Passfor Player 1 and play-\ningTakeat the last decision node for Player 2 (see Table 1). Additionally,\nwe consider an unbiased (level\u2013 k) reasoning type that recursively applies ( k\ntimes) a best response perturbed by uniform cognitive noise over t he player\u2019s\naction space, along with two biased (level\u2013 k) reasoning types. The biased\nreasoning types are implemented similarly to the unbiased one, but th e cog-\nnitive noise now directs the individual to end the game later or earlier t han\nwould be obtained by noiseless level\u2013 kreasoning in the ICG. As explained\nin the Introduction, the former will be referred to as a positively biased rea-\nsoning type, since each step of the reasoning process is biased by a desire\nfor future outcomes with a higher payo\ufb00 (corresponding to later s teps in the\nICG) compared to what would be calculated by noiseless level\u2013 kreasoning.\nIn opposition, this makes the latter a negatively biased reasoning type, as it\nis preferred to take before the step calculated by noiseless level\u2013 kreasoning.\nDetails are provided in section 4.\nPositively biased reasoning co-evolves with bounded ra-\ntionality.\nFigure 2 answers our \ufb01rst question: we show the outcome of the co -evolution\nbetween reasoning types and k-levels as dictated by the stationary distribu-\ntion of the stochastic evolutionary model for di\ufb00erent values of th e selection\nstrength \u03b2(see section 4) [30, 15]. To calibrate the output of our model, we\ndetermine the relevant level of cognitive noise \u03b5comparing our predictions\nwith the experimental data from Kawagoe and Takizawa [22]. The be st \ufb01t-\nting is provided for \u03b5\u22480.19, as shown in Figure 5 and Appendix A. For\n6\n\n--- Page 7 ---\ncomparison purposes, the same analysis and \ufb01tting are performed with the\ndata on the same game from the seminal work by McKelvey and Palfre y [2],\nproducing \u03b5\u22480.06 (see Appendix A for further details).\nPanelAshows the abundance of reasoning types as given by the station-\nary distribution for di\ufb00erent values of selection strength \u03b2and the calibrated\ncognitive noise \u03b5\u22480.19. The aim here is to understand how increasing\nthe selective pressure (i.e., higher \u03b2) a\ufb00ects the likelihood of ending up with\nany of the reasoning strategies studied here. When \u03b2\u22430, the evolution-\nary dynamics correspond to the process of neutral drift, thus e ach reasoning\nstrategy is almost equally present in the population. As \u03b2grows, the payo\ufb00\ndi\ufb00erences between strategies become increasingly relevant. As c an be ob-\nserved, the positively biased reasoning type takes over the popula tion, fully\ndominating when \u03b2\u22650.4. This preference for positively biased reasoning\ngrows together with a preference for performing k= 1 reasoning steps, as\ncan be seen in Panel B. In fact, after a minor peak in the frequency of k= 0\nindividuals, the k= 1 type eventually takes over the entire population.\nThe right panels in Figure 2 show the results for the same model \ufb01tte d\nto the experimental data in [2]. With a lower value of \u03b5(i.e.,\u03b5\u22480.06), the\nmistakes within the reasoning processes are less frequent than in t he previous\ncase. The di\ufb00erences between reasoning types are therefore no t as marked.\nHowever, positively biased reasoning is again the most frequent typ e under\nstrong selection ( \u03b2\u22651), being adopted by more than 60% of the population\n(PanelC). Moreover, the increased level of reasoning accuracy allows for\nthe development of a higher reasoning capacity, with k= 2 now being the\nmost frequent level of reasoning, adopted by 60 to 68% of the pop ulation\nunder strong selection, followed by k= 1 and k= 3, both with comparable\nfrequencies (Panel D).\nIn the following section, we examine the stochastic evolutionary dyn amic\nthat leads to this result in more detail. Before, we further observe that as\nthe stochasticity of the imitation process decreases (i.e., for large r values of\n\u03b2), higher levels of reasoning ( k= 4 and k= 5) progressively disappear\nfrom the population, meaning that the sophisticated individuals are r eplaced\nby the less sophisticated ones. This result is in agreement with both t heo-\nretical [38, 15] and experimental [16, 22] \ufb01ndings. Notably, higher levels of\nreasoning do not need to be explicitly penalized through the introduc tion of\nany computational cost because every additional backward step in the rea-\nsoning process has the implicit cost of propagating and amplifying the e\ufb00ect\nof cognitive noise. Therefore, the population eventually \ufb01nds the b est trade-\n7\n\n--- Page 8 ---\no\ufb00 between sophistication and propagation of errors, leading to th e presence\nof intermediate reasoning levels k= 1,2,3 when\u03b5is su\ufb03ciently small and to\nthe invasion of the level k= 1 at higher \u03b5.\nRemarkably, the pure strategy associated with the SPE(i.e., to stop the\ngame as early as possible) never manages to invade the others. This novel\noutcome is at odds with a previous evolutionary model proposed by R and\nand Nowak [30] which showed that this strategy would eventually pre vail\nunder strong selection when the population only plays pure strateg ies. Our\nmodel avoids this outcome because each strategy is a noisy introsp ective\nprocess [41, 42], where iterated conjectures about others\u2019 dec isions might\nundergo stochastic deviations from the deterministic rational pre dictions.\nThisresultthereforeunderlinesonceagaintheimportanceofthein troduction\nof cognitive noise, and therefore of the generated mixed strateg ies, to obtain\na more \ufb02exible and insightful model.\nA co-existence dynamic emerges from biased reasoning.\nIn Figure 3, we perform a more detailed analysis of the evolutionary d ynam-\nics to explain the previous observations. Panel Ashows the invasion diagram\n(i.e. the reduced Markov chain connecting all possible monomorphic p opula-\ntion states) for the calibrated values \u03b5= 0.19 and\u03b2= 0.063, corresponding\nto the settings indicated with the white dotted lines in Figure 2A and B.\nFor a better visualization, the strategies are restricted to k\u22642, as higher k-\nlevels cover a negligible portion of the stationary distribution. The inv asion\ndiagram is a useful tool to understand the dominance relationships between\nstrategies under the small-mutation limit approximation. A directed e dge\nfrom node ito nodejin this diagram, indicates that a single mutant adopt-\ning strategy jis able to \ufb01xate in a population of is with a probability higher\nthanrandomdrift[19]. AnEvolutionaryRobustStrategy(ERS)isas trategy\nwith no outgoing arrows [43].\nAswe cansee forthese parameter settings, there doesnotexist any ERS3.\nInstead, an interesting cycle is present, involving the three most f requent\nstrategies, namelythepositivelybiasedreasoningstrategywith k= 1,B+(1),\nthe no-reasoning ( NR) or payo\ufb00-maximising strategy, and k= 1 level of\nunbiased reasoning U(1). What is interesting is that the arrow connecting\n3As mentioned previously, when \u03b5\u22480.19 the positively biased reasoning type with\nk= 1 turns into an ERS for \u03b2 >0.4\n8\n\n--- Page 9 ---\nB+(1) andNRis pointing in both directions, which may indicate a potential\nfor co-existence of both reasoning strategies [44].\nThis hypothesis is con\ufb01rmed in Panel B, where we consider the replicator\ndynamic [45, 46] restricted to the three strategies NR,B+(1) andU(1), in\nwhich the population spends approximately 80% of the time according to the\nstationary distribution visualised in Panel A. The results of the replicator\ndynamic are visualised through the simplex covering all population con \ufb01g-\nurations for the three aforementioned strategies, including the a nticipated\ndynamics in each point of the simplex. One can clearly observe that a s table\nco-existencepointappearsforthecalibratedcognitivenoise \u03b5\u22480.19,wherein\n60% of the population uses level-1 positively biased reasoning ( B+(1)), while\nthe remaining 40% uses no reasoning ( NR). At each interior point of the sim-\nplex, the replicator dynamic is directed towards this novel equilibrium . We\nthus see that the game and its outcomes are transformed due to t he presence\nof biased and unbiased reasoning strategies [15, 47, 48], revealing t he impact\nthat (biased) reasoning strategies may have on decision-making.\nThis transformation of the game and resulting co-existence dynam ic is\nfurther explored in Panels CandDof Figure 3 where the complete Markov\nchainconnecting themonomorphicpopulationwith NRtotheonecontaining\nonlyB+(1) is analysed. Both plots show the interplay between the intensity\nof cognitive noise \u03b5and the co-existence point when the game is restricted\nto the two aforementioned strategies. As we can see, when \u03b5is su\ufb03ciently\nsmall (\u03b5\u22480.1), strong selection leads to the full invasion of individuals\nadopting the strategy B+(1). Larger values of \u03b5allow the emergence of a co-\nexistence point, where the fractions of the NRtype increases with \u03b5, until the\namount of cognitive errors is so large that performing any reasonin g becomes\nevolutionary detrimental. The results remain robust when studying the full\nMarkov chain under mutations (see Panel D).\nOverall, these results con\ufb01rm the importance of the positively biase d rea-\nsoning strategy within the context of the ICG. Indeed, the possib ility of\ndeveloping positively biased reasoning allows the population to enter a new\nstableequilibrium, where themajority ofthe populationis madeof pos itively\nbiased reasoners that co-exist with a minority of myopic payo\ufb00-max imizers\n(assuming a su\ufb03ciently small probability of reasoning mistakes). This novel\nequilibrium, while leading to a better agreement with the experimental refer-\nence, is also aligned with previous theoretical and behavioural stud ies argu-\ning that humans\u2019 sophistication in a population is often heterogeneo us and\nthat \u201cnaive\u201d types can survive and co-exist with more sophisticate d individ-\n9\n\n--- Page 10 ---\nuals [49, 16, 50].\nLonger exchanges promote the emergence of positively\nbiased reasoning.\nThe length of the ICG, represented here by the parameter L, is a key factor\nto secure the evolutionary success of positively biased reasoning. Indeed,\nlonger ICGs translate into a much larger resource to be shared amo ng the\nplayers because of the exponential growth inherent in the payo\ufb00 s tructure.\nIn Figure 4 we explore the e\ufb00ect of the intensity of cognitive noise \u03b5on the\nstationary distribution of our model when the selection strength \u03b2is \ufb01xed at\n0.063, for three values of L(L= 4,6,8 in Panels A,B,C, respectively).\nWhenL= 4, the di\ufb00erence in frequency between the unbiased, positively\nbiased, and negatively biased reasoning is negligible, regardless of th e inten-\nsity of cognitive noise. When L= 6, the incentive to end the game at later\nnodes is exponentially higher, leading to a prevalence of positively bias ed\nreasoning for a window of \u03b5values: in fact, more than half of the population\ndevelops a positivity bias within the range 0 .11< \u03b5 <0.2. Finally, when\nL= 8, the same e\ufb00ect is even more pronounced: now, the region wher e more\nthan half of the population chooses positively biased reasoning exte nds to\nthe range 0 .05< \u03b5 <0.2, and in the subset of values 0 .14< \u03b5 <0.17 the\nentire population adopts the strategy previously mentioned B+(1).\nIn each of the three scenarios, however, a larger probability of co gnitive\nerrors renders the reasoning process increasingly harmful, rega rdless of the\nreasoning process employed. This is particularly evident in the plot sh owing\nthedecay oftheaverage reasoning level \u00afk(Figure 4 D). The \ufb01gurereportsthe\nmeanandthestandarddeviationofthedistributionofreasoninglev els within\nthe population in the stationary state in function of the cognitive no ise.\nWe can see how, as \u03b5increases, the myopic payo\ufb00-maximizers progressively\nspreads across the population. This e\ufb00ect is more pronounced as t he length\nof the ICG increases to L= 8.\nOnce again, the presence of the strategy associated with the SPEis negli-\ngible, regardless of the value of \u03b5. This result is remarkable because this pure\nstrategy, despite being deterministic, is indirectly a\ufb00ected by the a mount of\nmistakes committedwithin thepopulationofinteracting agents: Ina popula-\ntion of sophisticated individuals who, nonetheless, make reasoning m istakes,\nit is better to take advantage of these mistakes and opt for a myop ic max-\n10\n\n--- Page 11 ---\nimisation of one\u2019s own payo\ufb00, rather than performing the rational r easoning\nprocess of backward induction.\n3 Conclusions\nWepresented amodel based ontheICGtostudy theco-evolutiono fstrategic\nreasoning with and without two cognitive biases, which were referre d to as\npositively and negatively biased reasoning, in the framework of Evolu tionary\nGame Theory. We showed how evolutionary dynamics in \ufb01nite populatio ns\ncan lead boundedly rational players in this game to develop a positivity\nbias while recursively reasoning about the potential move of their op ponents.\nFurthermore, the emergence of positively biased reasoning in this s equential\nsetting appears to be strongly linked to two factors, namely the pr esence of\nindividuals acting as myopic payo\ufb00 maximisers, and the promise of highe r\nfuture gains (captured here by the length of the ICG and the expo nential\ngrowth of the resource to be shared among the players).\nWhile our work was restricted to an evolutionary analysis of positively\nand negatively biased reasoning strategies in the ICG, the model ma y be\ninterpreted to re\ufb02ect speci\ufb01c cognitive and psychological phenom ena. As\nan example, the aforementioned reasoning strategies could be pot entially\nassociated with wishful thinking [51, 52, 53] and its counterpart defensive\npessimism [54, 55, 56]. Wishful thinking is described in the literature as\na distortion of cognitive forecasting processes towards more opt imistic ex-\npectations, and it implies the overestimation of the likelihood of desira ble\nevents. This concept therefore \ufb01ts, to a certain extent, our mo del, as the\nICG formalizes the partition of a growing resource between parties that hold\nbeliefs about each other and have desires for possibly di\ufb00erent out comes.\nWishful thinking, however, is an extremely broad phenomenon. Mor e-\nover, the related experimental literature exploring the link betwee n wishful\nthinking and strategic decision-making is rather limited and produced mixed\nresults (see e.g., [57, 58] for a review). It is therefore not obvious that wishful\nthinking is the source of the behavioural deviations presented her e or that\nthe model truly captures the intricacies of this concept. Alternat ive inter-\npretations, such as a risk-taking tendency [59, 60], may also align wit h the\nresults of our model. A more comprehensive analysis of the link betwe en the\nmodel and these cognitive interpretations is therefore needed, w hich is left\nfor future work.\n11\n\n--- Page 12 ---\nOur study was also limited to the investigation of cognitive biases in the\nform of consistent deviations from a rational judgment of the opp onent\u2019s\nfuture choice. The cognitive bias of each player was unequivocally tr ans-\nlated into a speci\ufb01c behaviour. In this sense, our study assumed th at the\nrelationshipbetween behavioural strategiesandcognitivebiases is unambigu-\nous, while each strategy could, in reality, be the outcome of multiple c ogni-\ntive processes and heuristics [36], as remarked above. Moreover , our model\nassumed a static belief framework in which individuals hold \ufb01xed prior be -\nliefs about their co-players. It also imposes that individuals share th e same\nbeliefs throughout the population and that all players use the same type of\nrecursive reasoning process, where opponents always possess a comparatively\nlower capacity for reasoning [15]. Future work can relax these ass umptions\nto examine how robust the results remain while also opening the door t o\nalternative models to explore other aspects of cognitive biases and related\npsychological phenomena that were not yet considered here.\nTo conclude, the insights provided by our model, while con\ufb01rming prev i-\nous experimental [61, 22] and theoretical [15, 38, 52] results, s how that the\ndeviations from the rational behaviour prescribed by game theory can be the\noutcome of evolutionary processes in which reasoning heuristics we re devel-\noped in order to better interact in complex and uncertain environme nts. In\nparticular, positively biased reasoning and bounded rationality prov ed to be\nadaptive features in the context of reciprocal exchanges of a sh ared resource\nthat grows over time, in line with theories of the evolution of human so cial\ncognitionclaimingthatwedeveloped thesenon-rationalbehaviours bymeans\nof our remarkable ability to understand the intentionality of our pee rs.\n4 Methods\n4.1 Notation\nLet us \ufb01rst introduce the notation that we will use throughout this section:\n\u2022The subscript i\u2208 {1,2}denotes the role of the player, while the clas-\nsical notation \u2212idenotes the role of the co-player;\n\u2022Airepresents the set of possible actions of the player in role i: specif-\nically,A1={0,2,...,L\u22122,L}andA2={1,3,...,L\u22121,L}with\n12\n\n--- Page 13 ---\n|A1|=|A2|= 1+L/2 (note that the action L, shared by both players,\nmeans to always play Pass);\n\u2022Ti\u2208 Aidenotes the step at which the player in role iwill end the game;\n\u2022\u03c3irepresents the probability distribution over the di\ufb00erent steps at\nwhich the player in role imay end the game.\n4.2 Strategies\nGiven an ICG of Lsteps, our game-theoretical model considers two pure\nstrategies and 3 \u00d7(L\u22121) generative strategies4. The pure strategies consist\nofthesub-gameperfectNashequilibrium (SPE) strategyandamyo pic payo\ufb00\nmaximisation strategy. The former will decide to end the game as ear ly as\npossible (in line with full backward induction). The latter aims at acquir ing\nthe highest possible personal reward, ignoring the potential choic es of the\nco-player. If L= 6, for instance, when acting as Player 1, this strategy will\nplayT1= 6 because \u03c01(6) = 25.6 is the highest payo\ufb00 of the game for Player\n1 (see Figure 1), without taking into account the other player\u2019s likely Take\nmove at the \ufb01fth node. Likewise, a myopic Player 2 would stop the gam e\nat the step T2= 5 to obtain the maximum payo\ufb00 \u03c02(5) = 12 .8, without\nconsidering that Player 1 would likely stop the game at the preceding n ode\n(see Figure 1 and Table 1).\nThe 3\u00d7(L\u22121) generative strategies are de\ufb01ned using the level\u2013 kframe-\nwork [21, 15]. Each generative strategy is determined by a value for kand\nthe type of (un)biased reasoning they will use to arrive at a decision . Each\nreasoning level kcorresponds to ksteps of backward induction reasoning,\nwhere players might deviate from the rational best response at ea ch reason-\ning step due to cognitive noise, de\ufb01ned by a parameter \u03b5\u2208[0,1]. Atk= 0,\nwhich corresponds to no-reasoning (NR), the strategy corresp onds to the\nmyopic payo\ufb00-maximizer explained earlier. When k >0, level\u2013kindividuals\nperform a recursive reasoning process assuming that the co-play er belongs to\nthe type k\u22121.\n4We use the term generative as opposed to mixedbecause in each interaction, these\nstrategies need to generate the action based on a noisy level\u2013 krecursive process. While\nthey implicitly encode a mixed strategy, i.e. a probability distribution ov er the action\nspace of both players, they are de\ufb01ned by the reasoning level k >0 and one of the three\nreasoning types, as it is further explained in Methods.\n13\n\n--- Page 14 ---\nIn a situation where individuals do not make any reasoning mistakes\n(\u03b5= 0), this process can be formulated as follows:\nTi(k) =/braceleftBigg\nargmax0\u2264t\u2264L\u03c0i(t),ifk= 0\nBRi(T\u2212i(k\u22121)),otherwise(1)\nwhereBRi(\u00b7) encodes the best response of Player igiven the action of Player\n\u2212i. This case is essentially analogous to [30], with the reasoning level k=\nL\u22121 being equivalent to the SPE strategy (see Table 1).\nSince we are interested in the evolution of cognitive biases and strat egic\nreasoning, we focus on the case \u03b5 >0: in particular, at each reasoning\nstep, we let players deviate from the best-response with probabilit y\u03b5\u2208\n[0,1] [15], i.e., Player iwill now choose their action according to a noisy\nbest response, NBRi(\u00b7), which replaces BRi(\u00b7) in Equation 1. Resuming the\nexample mentioned above, if Player 2 now performs one reasoning st ep (k=\n1), they will take into account that a \ufb01ctional Player 1 with k= 0 follows\nthe pure strategy T1(0) = 6, so Player 2 will adopt strategy T2(1) = 5 with\nprobability 1 \u2212\u03b5, but will deviate from it with probability \u03b5. Depending on\nthe reasoning type, these deviations can occur uniformly on the wh ole action\nspace if the reasoning process is unbiased, or they can be skewed t owards\nearlier or later steps in case of negatively or positively biased reason ing,\nrespectively.\nEach reasoning process will thus produce a role-dependent proba bility\ndistribution over the actions of each player, \u03c31(k) and\u03c32(k), corresponding\nto the probability distributions over the action spaces of Player 1 an d Player\n2, respectively:\n\u03c31(k) = [P(T1(k) = 0),P(T1(k) = 2), ...,P(T1(k) =L)],\n\u03c32(k) = [P(T2(k) = 1),P(T2(k) = 3), ...,P(T2(k) =L)].\nThe recursive reasoning in Equation 1 then corresponds to an itera tive ap-\nplication of the law of total probability, where each element of the ve ctors\n\u03c31(k) and\u03c32(k) equals:\nP(Ti(k) =ti) = (2)/summationtext\nt\u2212i\u2208A\u2212iP(NBRi(t\u2212i) =ti|T\u2212i(k\u22121) =t\u2212i)\u00b7P(T\u2212i(k\u22121) =t\u2212i)\nwithi\u2208 {1,2},k >0, andti\u2208 Ai. The overall probability of Player i\nplaying action tiis thus the sum of the probabilities that tiis chosen as the\n14\n\n--- Page 15 ---\nresponse to a \ufb01ctional level\u2013( k\u22121) opponent playing the action t\u2212i, over all\npossible actions in the set A\u2212i.\nItcanbeshownthatthestrategyofaplayercoveringbothrolesw ithequal\nprobability can be computed through the following formula (see Appe ndix B\nfor further details):\n\u03c3(k) =\u03c3(0)\u00b7M(\u03b5)k, (3)\nwhere\u03c3(k) with 0\u2264k\u2264L\u22121 isthe concatenationof thetwo role-dependent\nstrategy vectors \u03c31(k) and\u03c32(k), andM(\u03b5) is a matrix which depends on the\nintensity of the cognitive noise \u03b5and encapsulates the noisy best responses\nfor both roles.\nEach strategy in our model is therefore uniquely determined by thr ee\ncomponents of the reasoning process: (i) the starting point, \u03c3(0); (ii) the rea-\nsoning kernel, M(\u03b5); and (iii) the depth of the reasoning process, 0 \u2264k < L.\nThis framework has an intuitive and straightforward interpretatio n: each in-\ndividual has a prior behaviour ,\u03c3(0), about the action to choose without any\nreasoning, and they modify it by applying the reasoning kernel M(repre-\nsentative of their mind) iteratively for ktimes. As stated previously, we \ufb01x\nthe prior belief \u03c3(0) of each individual such that k= 0 corresponds to an\nagent who myopically aims at maximising the payo\ufb00 of the game, leading t o\n\u03c3(0) = [0,0,0,1,0,0,1,0] forL= 6.\nTo study the evolution of cognitive biases, we propose the following r ea-\nsoning kernels:\n\u2022anunbiased reasoning kernel, MU(\u03b5), where the best response is chosen\nat each step with probability 1 \u2212\u03b5while any other action is chosen with\nuniform probability 2 \u03b5/L;\n\u2022anegatively biased reasoning kernel, MB\u2212(\u03b5), where deviations from\nthe best response only happen to shift towards earlier nodes of th e\ngame, i.e., lower-payo\ufb00 outcomes;\n\u2022apositively biased reasoning kernel, MB+(\u03b5), where deviations from the\nbest response only happen in direction of later nodes, i.e., outcomes\nwhere payo\ufb00s are higher but uncertain.\nWedenotethelevel\u2013 kstrategiesofunbiased, positivelybiased, andnegatively\nbiased reasoning by U(k),B+(k), andB\u2212(k), respectively. In Appendix B\nwe report the three matrices MU(\u03b5),MB+(\u03b5), andMB\u2212(\u03b5) in the case where\nL= 6.\n15\n\n--- Page 16 ---\n4.3 Payo\ufb00s\nWe now describe the computation of the payo\ufb00s resulting from the in ter-\naction between two strategies. Let us suppose two players, Alice a nd Bob,\nadopt strategies \u03c3Aand\u03c3Brespectively. As stated previously, each of these\nvectors consists of a pair of role-dependent probability distributio ns, namely\n(\u03c31A,\u03c32A) and (\u03c31B,\u03c32B).\nHere, we assume that Alice and Bob play against each other covering\nboth roles with equal probability, so that the game becomes symmet ric [30].\nThis means that, for instance, the expected payo\ufb00 of Alice, \u03a0 A(\u03c3A,\u03c3B), is\ngiven by the average between the expected payo\ufb00 she would obtain while\nplaying as Player 1 against Bob playing as Player 2 and the expected pa yo\ufb00\nin the opposite scenario. Thus, we obtain the following equation:\n\u03a0A(\u03c3A,\u03c3B) =1\n2L/summationdisplay\nt=0/braceleftbig\n\u03c01(t)\u00b7P/parenleftbig\nTmin\n1=t/parenrightbig\n+\u03c02(t)\u00b7P/parenleftbig\nTmin\n2=t/parenrightbig/bracerightbig\n,(4)\nwhereTmin\n1andTmin\n2are the two random variables associated with the dis-\ntribution of the terminal node of the game on the two admissible scen arios,\nwhere Alice (Bob) plays as Player 1 (2) and Player 2 (1), respectively :\nTmin\n1:= min{\u03c31A,\u03c32B}, Tmin\n2:= min{\u03c32A,\u03c31B}.\nNote that, since these two random variables are independent and d e\ufb01ned\nover the same support, the cumulative distribution function of the minimum\nbetween the two can be computed analytically through the following e qua-\ntion:\nP(Tmin\ni\u2264t) = 1\u2212P(\u03c3iA> t)P(\u03c3\u2212iB> t).\n4.4 Evolutionary dynamics\nAsmentioned intheIntroduction, we adoptanapproachbased onE volution-\nary GameTheory to understand how cognitive biases and strategic reasoning\nmight have co-evolved in the long term. In brief, this approach appr oximates\nthe evolution of the behaviour of a population of Zindividuals interacting\namong each others according to their given strategies, via analytic al methods\n16\n\n--- Page 17 ---\nor numerical simulations [62]. Borrowing ideas from evolutionary biolog y, a\nstrategy can propagate within the population if it is associated with h igher\n\ufb01tness, i.e., yield a higher expected payo\ufb00, than the others.\nAt each generation step, one individual Xis randomly chosen to update\ntheir strategy by either undergoing a stochastic mutation with pro bability\u00b5\nor by imitating a better co-player [63]. In the latter case, another individual\nYis randomly sampled from the population to act as a potential role mod el,\nand will be imitated with probability p= 1/(1+exp( \u03b2(\u03a0X\u2212\u03a0Y))), which\nincreases with the \ufb01tness di\ufb00erence between YandX[64]. The parameter\n\u03b2represents the intensity of selection, i.e., the strength of imitation : when\n\u03b2= 0, imitation occurs with 50% chance, corresponding to the proces s of\nneutral drift; when \u03b2is large, imitation becomes sensitive to the slightest\n\ufb01tness di\ufb00erence, leading to an almost deterministic evolutionary pr ocess.\nThe number of states of this birth-death process, however, quic kly becomes\nintractable via analytical methods.\nA possible solution is the so-called small-mutation limit , i.e., the case\nwhere mutations are negligible ( \u00b5\u21920) [65]. This approximation allows\nus to reduce the size of the Markov chain to the number of strateg ies of\nthe game. Indeed, with this approximation, the time interval betwe en two\nmutations is su\ufb03ciently large that evolution will lead to the \ufb01xation of o ne\nstrategy in the population before the next mutation leads to the ap pearance\nof a new strategy. Thus, at any time, there will be at most two stra tegies\nsimultaneously present in the population. The rare-mutation limit lead s to\nan embedded Markov chain whose states correspond to the di\ufb00ere nt homo-\ngeneous con\ufb01gurations of the population in which everyone plays th e same\nstrategy. Most results in this work, except for Panels B-Dof Figure 3, are\nobtained under the small-mutation limit.\nA further approximation, used in Panels Bof Figure 3 is given by the\nlimit of in\ufb01nite populations. The dynamics in this case is represented by the\nreplicator equation [45, 46]. This di\ufb00erential equation expresses a d etermin-\nistic selection process where the frequency of a type i,xi, increases if it has\nhigher \ufb01tness, \u03a0 i, than the average \ufb01tness of the population \u03a0. In formulas,\n\u02d9xi=xi(\u03a0i(x)\u2212\u03a0(x)). When the gradient is 0, i.e., \u02d9 xi= 0, we have an\nequilibrium point. If the gradients in a small neighbourhood of an equilib -\nriumx\u2217point toward x\u2217, the equilibrium is said to be evolutionary stable.\nThis de\ufb01nition means that an Evolutionary Stable State is robust to s mall\nchanges in the population, i.e., a mutant will not drive the population to a\ndi\ufb00erent state. This solution concept, more strict than the well kn own Nash\n17\n\n--- Page 18 ---\nequilibrium, allows to characterize complex evolutionary processes t hrough\nrelatively simple di\ufb00erential equations.\n4.5 Code availability\nThe software implementation of the evolutionary processes is base d on EGT-\nTools5[20], an open-source hybrid C++/Python library that provides both\nanalytical and numerical methods to study game-theoretical pro blems within\nthe framework of Evolutionary Game Theory. The code to reprodu ce all\nthe results presented in this work can be found at the following GitHu b\nrepository[66].\n5 Acknowledgments\nThe authors gratefully acknowledge the research support of the F.R.S-FNRS\n(project grant 40007793). TL further acknowledges the suppo rt of the Ser-\nvice Public de Wallonie Recherche (grant 2010235\u2013ARIAC) by DigitalWa l-\nlonia4.ai and the Flemish Government through the AI Research Prog ram.\nEFD is supported by an F.W.O. Senior Postdoctoral Grant (12A7825 N).\nThe authors also thank Axel Abels and the anonymous reviewers fo r their\nuseful comments and suggestions, which allowed us to improve this a rticle.\n5https://egttools.readthedocs.io/en/latest/\n18\n\n--- Page 19 ---\n6 Figures & Tables\n6.1 Figures\nTurns: Pl.1 Pl.2 Pl.1 Pl.2 Pl.1 Pl.2\nStep 6\n\u03c01(6) = 25.6\n\u03c02(6) = 6.4P\nStep 5\n\u03c01(5) = 3.2\n\u03c02(5) = 12.8TP\nStep 4\n\u03c01(4) = 6.4\n\u03c02(4) = 1.6TP\nStep 3\n\u03c01(3) = 0.8\n\u03c02(3) = 3.2TP\nStep 2\n\u03c01(2) = 1.6\n\u03c02(2) = 0.4TP\nStep 1\n\u03c01(1) = 0.2\n\u03c02(1) = 0.8TP\nStep 0\n\u03c01(0) = 0.4\n\u03c02(0) = 0.1T\nFigure 1: Extensive form of the six-step Incremental Centipede G ame with\nexponential growth. The notation \u03c0i(t) denotes the payo\ufb00 Player iwould get\nif the game ends at Step t.\n6.2 Tables\nk= 0 k= 1 k= 2 k= 3 k= 4 k= 5\nPl.1argmax0\u2264t\u22646\u03c01(t) = 6BR1(5) = 4 BR1(5) = 4 BR1(3) = 2 BR1(3) = 2 BR1(1) = 0\nPl.2argmax0\u2264t\u22646\u03c02(t) = 5BR2(6) = 5 BR2(4) = 3 BR2(4) = 3 BR2(2) = 1 BR2(2) = 1\nTable 1: Representation of backward induction in a six-step Centipe de Game\nas a level\u2013 krecursive reasoning process. From left to right, each column\ncontains the actions of Player 1 (top) and Player 2 (bottom) as the y are de-\ntermined by a deterministic introspective process with an increasing number\nof reasoning steps. Such process starts at k= 0 (left), where players do not\nperform any reasoning and will simply end the game in correspondenc e of\nthe highest personal payo\ufb00. For k >0, players choose the best response to\na \ufb01ctional level\u2013( k\u22121) player. When k= 5 (right), players perform the\nfull backward induction process, thus the action generated by th e reasoning\nprocess corresponds to the outcome predicted by the subgame p erfect Nash\nequilibrium (SPE).\n19\n\n--- Page 20 ---\n\u03b2 (strength of selection)0.00.20.40.60.81.0frequency\u03b2*\n= 0.063high cognitive noise, \u03b5*\n= 0.186\nno reasoning (k=0)\nunbiased  reasoning\nneg.-biased reasoning\npos.-biased reasoning\nsubgame perfect eq.\n\u03b2 (strength of selection)\nfrequency\u03b2*\n= 0.032low cog itive  oise, \u03b5*\n= 0.062\n10\u22124\n10\u22123\n10\u22122\n10\u22121\n100\n101\n\u03b2 (strength  of selection)0.00.20.40.60.81.0frequency\u03b2*\n= 0.063k=0\nk=1\nk=2\nk=3\nk=4\nk=5\nSPE\n10\u22124\n10\u22123\n10\u22122\n10\u22121\n100\n101\n\u03b2 (stre gth of selectio )\nfreque c*\u03b2*\n= 0.032A C\nB D\nFigure 2: Positively biased reasoning co-evolves with bounded ration ality.\nThe distribution of reasoning types and reasoning levels in the six-st ep ICG\nis shown for variable selection strength \u03b2, under high ( \u03b5\u2217= 0.186) and low\n(\u03b5\u2217= 0.062) probability of reasoning errors (panels A,BandC,D, respec-\ntively). For each value of \u03b2, we compute the stationary distribution \u03c6of\nour dynamical system under the assumption of rare mutations. Th e frequen-\ncies of each strategy are aggregated by reasoning kernel, fker=/summationtextL\nk=1\u03c6sker,k\nforker\u2208 {U,B+,B\u2212}, and by reasoning level, fk=/summationtext\nker\u2208{U,B+,B\u2212}\u03c6sker,k\nfor 1\u2264k\u2264L(panelsA,CandB,D, respectively). For completeness, the\n\ufb01gures also include the frequency of the pure strategy associate d with no\nreasoning (i.e., reasoning level k= 0) and the sub-game perfect equilibrium\n(SPE) strategy of stopping the game as early as possible. The white dotted\nlines correspond to the selection strength \u03b2\u2217of optimal \ufb01tting with the data\nin [22] and [2] (panels A,BandC,D, respectively). The population size is\n\ufb01xed to 100 individuals.\n20\n\n--- Page 21 ---\nNRU (1)U (2)\nB\u2212\n(1)\nB\u2212\n(2)\nB+\n(1)B+\n(2)0.170.130.02\n0.09\n0.02\n0.500.05B+\n(1)U (1)\nNR\n0.0 0.2 0.4 0.6 0.8 1.0\nfrequency  of B+\n(1)\u22120.050.000.050.10g adient of selectionselection st ength \u03b2 = 1\n\u03b5 = 0.1\n\u03b5 = 0.15\n\u03b5 = 0.186\n\u03b5 = 0. 2\n\u03b5 = 0. 25\n0.0 0.2 0.4 0.6 0.8 1.0\nf equency of B+\n(1)0.0000.0250.0500.0750.1000.1250.150\nstationa y dist ibutionselection st ength \u03b2 = 1, mutation  ate \u03bc = 0.01\n0.010.020.030.040.050.060.070.08g adient of selectionA B\nC D\nFigure 3: No-reasoning and level\u20131 positively biased reasoning co-ex ist un-\nder limited cognitive noise. Panel Ashows the invasion diagram related to\nthe evolutionary dynamics of our model under the small mutation limit , for\n\u03b2= 0.063 and \u03b5= 0.186. The strategies are limited to k\u22642, and when\nk >0 the reasoning kernel can be unbiased ( U), positively biased ( B+) or\nnegatively biased ( B\u2212). The edges in the graph represent the transitions be-\ntween di\ufb00erent monomorphic states: an outgoing edge from strat egyAtoB\nmeans that Ais invaded by B. The number next to each node is the fraction\nof time spent in each monomorphic state at the stationary regime. P anelB\nfocuses on the evolutionary dynamics in an in\ufb01nite population betwee n the\nthree most frequent strategies in Panel A, i.e.,B+(1),NR, andU(1). We\nplot the gradient of selection and the \ufb01xed points associated to the replicator\nequation. Theblackandwhitecirclesrepresent stableandunstable equilibria\nrespectively, whereas gray circles are saddle points. The arrows in dicate the\ndirection of the selective pressure. Finally, Panels CandDshow the e\ufb00ect\nof the cognitive noise \u03b5on the location of the co-existence point between the\ntwo strategies B+(1) andNRunder strong selection ( \u03b2= 1). The population\nsize in Panels A,C,DisZ= 100.\n21\n\n--- Page 22 ---\n0.0 0.1 0.2 0.3\n\u03b5 (inten ity of cognitive noi e)0.00.20.40.60.81.0frequencyL= 4\n0.0 0.1 0.2 0.3\n\u03b5 (inten ity of cognitive noi e)\u03b5*\n= 0.186L= 6\n0.0 0.1 0.2 0.3\n\u03b5 (inten ity of cognitive noi e)0.00.20.40.60.81.0\nfrequencyL= 8\n0.00 0.05 0.10 0.15 0.20 0.25 0.30\n\u03b5 (inten ity of cognitive noi e)0 01 12 23 34 4average rea oning level \u0304\nkL=4\nL=6\nL=8A B C\nDno rea oning unbia ed rea oning neg.-bia ed rea oning po .-bia ed rea oning  ubgame perfect eq.\nFigure 4: Longer exchanges promote the emergence of positively b iased rea-\nsoning. The e\ufb00ect of the number of steps of the ICG, represente d by the\nparameter L\u2208 {4,6,8}, on the evolution of reasoning kernels (panels A-C)\nand reasoning levels (panel D) is shown for variable cognitive noise \u03b5. For\neach value of \u03b5, we compute the stationary distribution \u03c6of our dynamical\nsystem under the assumption of rare mutations. In panels A-C, the frequen-\ncies of each strategy are aggregated by reasoning kernel, fker=/summationtextL\nk=1\u03c6sker,k\nforker\u2208 {U,B+,B\u2212}. For completeness, the \ufb01gures also include the fre-\nquency of the pure strategy associated with no reasoning (i.e., rea soning level\nk= 0) and the sub-game perfect equilibrium (SPE) strategy of stopp ing the\ngame as early as possible. In panel D, we report the average reasoning level\nof the population, \u00afk=/summationtextL\nk=1kfkwherefk=/summationtext\nker\u2208{U,B+,B\u2212}\u03c6sker,k, along\nwith its standard deviation plotted in form of error bars. The white d otted\nline in panel Bcorresponds to the value of cognitive noise \u03b5\u2217of optimal \ufb01t-\nting with the data in [22]. The population size is \ufb01xed to 100 individuals,\nand the strength of selection is \u03b2\u2217= 0.063.\n22\n\n--- Page 23 ---\nReferences\n[1] Camerer CF. 2011 Behavioral Game Theory: Experiments in Strategic\nInteraction . Roundtable Series in Behavioral Economics. Princeton, NJ:\nPrinceton University Press. Reprint edition.\n[2] McKelvey RD, Palfrey TR. 1992 An Experimental Study of the Cen -\ntipede Game. Econometrica 60, 803. (10.2307/2951567)\n[3] Rand DG, Peysakhovich A, Kraft-Todd GT, Newman GE, Wurzbac her\nO, Nowak MA, Greene JD. 2014 Social heuristics shape intuitive coop -\neration.Nature Communications 5, 3677. (10.1038/ncomms4677)\n[4] Oosterbeek H, Sloof R, Van De Kuilen G. 2004 Cultural Di\ufb00erences in\nUltimatumGameExperiments: Evidence fromaMeta-Analysis. Experi-\nmental Economics 7, 171\u2013188.(10.1023/B:EXEC.0000026978.14316.74)\n[5] Grosskopf B, Nagel R. 2008 The two-person beauty contest. Games and\nEconomic Behavior 62, 93\u201399. (10.1016/j.geb.2007.03.004)\n[6] CamererCF,HoTH,ChongJK.2004pp.120\u2013180.In Behavioural Game\nTheory: Thinking, Learning and Teaching , pp. 120\u2013180. London: Pal-\ngrave Macmillan UK. (10.1057/9780230523371 8)\n[7] Jensen K, Call J, Tomasello M. 2007 Chimpanzees Are Ratio-\nnal Maximizers in an Ultimatum Game. Science 318, 107\u2013109.\n(10.1126/science.1145850)\n[8] Bornstein BH, Emler AC. 2001 Rationality in medical decision\nmaking: a review of the literature on doctors\u2019 decision-making\nbiases.Journal of Evaluation in Clinical Practice 7, 97\u2013107.\n(10.1046/j.1365-2753.2001.00284.x)\n[9] Montibeller G, Von Winterfeldt D. 2015 Cognitive and Motivational\nBiases in Decision and Risk Analysis. Risk Analysis 35, 1230\u20131251.\n(10.1111/risa.12360)\n[10] Marshall JA, Trimmer PC, Houston AI, McNamara JM. 2013 On ev olu-\ntionary explanations of cognitive biases. Trends in Ecology & Evolution\n28, 469\u2013473. (10.1016/j.tree.2013.05.013)\n23\n\n--- Page 24 ---\n[11] Trivers R. 2011 Deceit and self-deception: fooling yourself the better to\nfool others . London: Allen Lane.\n[12] Von Hippel W, Trivers R. 2011 The evolution and psychol-\nogy of self-deception. Behavioral and Brain Sciences 34, 1\u201316.\n(10.1017/S0140525X10001354)\n[13] Rusch T, Steixner-Kumar S, Doshi P, Spezio M, Gl\u00a8 ascher J. 20 20\nTheory of mind and decision science: Towards a typology of\ntasks and computational models. Neuropsychologia 146, 107488.\n(10.1016/j.neuropsychologia.2020.107488)\n[14] McKay RT, Dennett DC. 2009 The evolution of misbelief. Behavioral\nand Brain Sciences 32, 493\u2013510. (10.1017/S0140525X09990975)\n[15] Lenaerts T, Saponara M, Pacheco JM, Santos FC. 2024 Evolut ion of a\ntheory of mind. iScience 27, 108862. (10.1016/j.isci.2024.108862)\n[16] Camerer CF, Ho TH, Chong JK. 2004 A Cognitive Hierarchy\nModel of Games. The Quarterly Journal of Economics 119, 861\u2013898.\n(10.1162/0033553041502225)\n[17] Smith JM, Price GR. 1973 The Logic of Animal Con\ufb02ict. Nature246,\n15\u201318. (10.1038/246015a0)\n[18] Smith JM. 1982 Evolution and the Theory of Games . Cambridge Uni-\nversity Press.\n[19] Sigmund K. 2010 The calculus of sel\ufb01shness . Princeton series in theoret-\nical and computational biology. Princeton: Princeton University Pr ess.\nOCLC: ocn319157195.\n[20] Fern\u00b4 andez Domingos E, Santos FC, Lenaerts T. 2023 EGTtoo ls:\nEvolutionary game dynamics in Python. iScience 26, 106419.\n(10.1016/j.isci.2023.106419)\n[21] Stahl DO. 1993 Evolution of Smartn Players. Games and Economic Be-\nhavior5, 604\u2013617. (10.1006/game.1993.1033)\n[22] Kawagoe T, Takizawa H. 2012 Level-k analysis of experimental c en-\ntipede games. Journal of Economic Behavior & Organization 82, 548\u2013\n566. (10.1016/j.jebo.2012.03.010)\n24\n\n--- Page 25 ---\n[23] Nax HH, Newton J. 2022 Deep and shallow thinking in the long run.\nTheoretical Economics 17, 1501\u20131527. (10.3982/TE4824)\n[24] Aumann RJ. 1997 Rationality and Bounded Rationality. Games and\nEconomic Behavior 21, 2\u201314. (10.1006/game.1997.0585)\n[25] Rosenthal RW. 1981 Games of perfect information, predator y pricing\nand the chain-store paradox. Journal of Economic Theory 25, 92\u2013100.\n(10.1016/0022-0531(81)90018-1)\n[26] Rapoport A, Stein WE, Parco JE, Nicholas TE. 2003 Equilibrium play\nand adaptive learning in a three-person centipede game. Games and\nEconomic Behavior 43, 239\u2013265. (10.1016/S0899-8256(03)00009-5)\n[27] Murphy RO, Rapoport A, Parco JE. 2004 Population Learning of Co-\noperative Behavior in a Three-Person Centipede Game. Rationality and\nSociety16, 91\u2013120. (10.1177/1043463104039876)\n[28] Fey M, McKelvey RD, Palfrey TR. 1996 An experimental study of\nconstant-sum centipede games. International Journal of Game Theory\n25, 269\u2013287. (10.1007/BF02425258)\n[29] Palacios-Huerta I, Volij O. 2009 Field Centipedes. American Economic\nReview99, 1619\u20131635. (10.1257/aer.99.4.1619)\n[30] Rand DG, Nowak MA. 2012 Evolutionary dynamics in \ufb01nite popu-\nlations can explain the full range of cooperative behaviors observe d\nin the centipede game. Journal of Theoretical Biology 300, 212\u2013221.\n(10.1016/j.jtbi.2012.01.011)\n[31] McKelvey RD, Palfrey TR. 1995 Quantal Response Equilibria for\nNormal Form Games. Games and Economic Behavior 10, 6\u201338.\n(10.1006/game.1995.1023)\n[32] Mckelvey RD, Palfrey TR. 1998 Quantal Response Equilibria\nfor Extensive Form Games. Experimental Economics 1, 9\u201341.\n(10.1023/A:1009905800005)\n[33] B\u00b4 ela E. 2022 Altruism and Ambiguity in the Centipede game.\n(10.31235/osf.io/93p8s)\n25\n\n--- Page 26 ---\n[34] Krockow EM, Colman AM, Pulford BD. 2016 Exploring cooperation\nandcompetitionintheCentipedegamethroughverbalprotocolan alysis.\nEuropean Journal of Social Psychology 46, 746\u2013761.(10.1002/ejsp.2226)\n[35] Gamba A, Regner T. 2019 Preferences-dependent learning in t he cen-\ntipede game: The persistence of mistrust. European Economic Review\n120, 103316. (https://doi.org/10.1016/j.euroecorev.2019.103316)\n[36] Fawcett TW, Fallenstein B, Higginson AD, Houston AI, Mallpress D E,\nTrimmer PC, McNamara JM. 2014 The evolution of decision rules\nin complex environments. Trends in Cognitive Sciences 18, 153\u2013161.\n(10.1016/j.tics.2013.12.012)\n[37] Tversky A, Kahneman D. 1974 Judgment under Uncertainty: H euristics\nandBiases: Biases injudgments reveal someheuristics ofthinking u nder\nuncertainty.. Science185, 1124\u20131131. (10.1126/science.185.4157.1124)\n[38] De Weerd H, Verbrugge R, Verheij B. 2013 How much does it help t o\nknow what she knows you know? An agent-based simulation study.\nArti\ufb01cial Intelligence 199-200, 67\u201392. (10.1016/j.artint.2013.05.004)\n[39] Devaine M, Hollard G, Daunizeau J. 2014 Theory of Mind: Did Evolu-\ntion Fool Us?. PLoS ONE 9, e87619. (10.1371/journal.pone.0087619)\n[40] Basu K. 1994 The Traveler\u2019s Dilemma: Paradoxes of Rationality in\nGame Theory. The American Economic Review 84, 391\u2013395.\n[41] Goeree JK, Holt CA. 1999 Stochastic game theory: For playing g ames,\nnot just for doing theory. Proceedings of the National Academy of Sci-\nences96, 10564\u201310567. (10.1073/pnas.96.19.10564)\n[42] Goeree JK, Holt CA. 2004 A model of noisy introspection. Games and\nEconomic Behavior 46, 365\u2013382. (10.1016/S0899-8256(03)00145-3)\n[43] Stewart AJ, Plotkin JB. 2013 From extortion to generosity, ev olution in\nthe Iterated Prisoner\u2019s Dilemma. Proceedings of the National Academy\nof Sciences 110, 15348\u201315353. (10.1073/pnas.1306246110)\n[44] Auger P, De La Parra R, S\u00b4 anchez E. 1998 Hawk-dove game and com-\npetition dynamics. Mathematical and Computer Modelling 27, 89\u201398.\n(10.1016/S0895-7177(98)00009-0)\n26\n\n--- Page 27 ---\n[45] Schuster P, SigmundK.1983Replicatordynamics. Journal of theoretical\nbiology100, 533\u2013538.\n[46] Cressman R, Tao Y. 2014 The replicator equation and other gam e dy-\nnamics.Proceedings of the National Academy of Sciences 111, 10810\u2013\n10817.\n[47] Nowak MA. 2006 Five rules for the evolution of cooperation. science\n314, 1560\u20131563.\n[48] Taylor C, Nowak MA. 2007 Transforming the dilemma. Evolution 61,\n2281\u20132292.\n[49] Heller Y. 2015 Three steps ahead: Three steps ahead. Theoretical Eco-\nnomics10, 203\u2013241. (10.3982/TE1660)\n[50] CrawfordVP. 2003Lying forStrategicAdvantage: Rationala ndBound-\nedly Rational Misrepresentation of Intentions. American Economic Re-\nview93, 133\u2013149. (10.1257/000282803321455197)\n[51] Aue T, Nusbaum HC, Cacioppo JT. 2012 Neural correlates of wis h-\nful thinking. Social Cognitive and A\ufb00ective Neuroscience 7, 991\u20131000.\n(10.1093/scan/nsr081)\n[52] Neuman R, Ra\ufb00erty A, Gri\ufb03ths T. 2014 A bounded rationality acc ount\nofwishful thinking.In Proceedings of the annual meeting of the Cognitive\nScience Society vol. 36.\n[53] YildizM. 2007Wishful Thinking inStrategicEnvironments. The Review\nof Economic Studies 74, 319\u2013344. (10.1111/j.1467-937X.2007.00423.x)\n[54] Vosgerau J. 2010 How prevalent is wishful thinking? Misattribu-\ntion of arousal causes optimism and pessimism in subjective prob-\nabilities.. Journal of Experimental Psychology: General 139, 32\u201348.\n(10.1037/a0018144)\n[55] Sanna LJ. 1998 Defensive Pessimism and Optimism: The Bitter-\nSweet In\ufb02uence of Mood on Performance and Prefactual and\nCounterfactual Thinking. Cognition & Emotion 12, 635\u2013665.\n(10.1080/026999398379484)\n27\n\n--- Page 28 ---\n[56] Bateson M, Desire S, Gartside S, Wright G. 2011 Agitated Honey bees\nExhibit Pessimistic Cognitive Biases. Current Biology 21, 1070\u20131073.\n(10.1016/j.cub.2011.05.017)\n[57] Krizan Z, Windschitl PD. 2009 Wishful Thinking about the Future :\nDoesDesireImpactOptimism?. Social and PersonalityPsychologyCom-\npass3, 227\u2013243. (10.1111/j.1751-9004.2009.00169.x)\n[58] Krizan Z, Windschitl PD. 2007 The in\ufb02uence of outcome de-\nsirability on optimism.. Psychological Bulletin 133, 95\u2013121.\n(10.1037/0033-2909.133.1.95)\n[59] Dekel E, Scotchmer S. 1999 On the Evolution of Attitudes towa rds Risk\nin Winner-Take-All Games. Journal of Economic Theory 87, 125\u2013143.\n(https://doi.org/10.1006/jeth.1999.2537)\n[60] Brocas I, Carrillo JD. 2025Why do children pass inthe centipede g ame?\nCognitive limitations v. risk calculations. Games and Economic Behav-\nior150, 295\u2013311. (https://doi.org/10.1016/j.geb.2025.01.003)\n[61] Johnson DDP, Fowler JH. 2011 The evolution of overcon\ufb01dence .Nature\n477, 317\u2013320. (10.1038/nature10384)\n[62] Fatima S, Jennings NR, Wooldridge M. 2024 Learning to Resolve So cial\nDilemmas: A Survey. Journal of Arti\ufb01cial Intelligence Research 79,\n895\u2013969. (10.1613/jair.1.15167)\n[63] Fudenberg D, Imhof LA. 2006 Imitation processes with small mu tations.\nJournal of Economic Theory 131, 251\u2013262. (10.1016/j.jet.2005.04.006)\n[64] Traulsen A, Nowak MA, Pacheco JM. 2006 Stochastic dynam-\nics of invasion and \ufb01xation. Physical Review E 74, 011909.\n(10.1103/PhysRevE.74.011909)\n[65] Hindersin L, Wu B, Traulsen A, Garc\u00b4 \u0131a J. 2019 Computation and S imu-\nlation of Evolutionary Game Dynamics in Finite Populations. Scienti\ufb01c\nReports9, 6946. (10.1038/s41598-019-43102-z)\n[66] Saponara M. 2025 MarcoSaponara/centipede-bias: First pub lic release.\n(10.5281/zenodo.15838520)\n28\n\n--- Page 29 ---\n[67] Yamagishi T, Yamagishi M. 1994 Trust and commitment in the\nUnited States and Japan. Motivation and Emotion 18, 129\u2013166.\n(10.1007/BF02249397)\n[68] Krockow EM, Takezawa M, Pulford BD, Colman AM, Smithers\nS, Kita T, Nakawake Y. 2018 Commitment-enhancing tools in\nCentipede games: Evidencing European\u2013Japanese di\ufb00erences in\ntrust and cooperation. Judgment and Decision Making 13, 61\u201372.\n(10.1017/S1930297500008822)\n[69] Krockow EM, Colman AM, Pulford BD. 2016 Cooperation in re-\npeated interactions: A systematic review of Centipede game exper i-\nments, 1992\u20132016. European Review of Social Psychology 27, 231\u2013282.\n(10.1080/10463283.2016.1249640)\n[70] Krockow EM, Takezawa M, Pulford BD, Colman AM, Kita T. 2017 Co -\noperation and Trust in Japanese and British Samples: Evidence From\nIncomplete Information Games. International Perspectives in Psychol-\nogy6, 227\u2013245. (10.1037/ipp0000074)\nA Fitting with experimental data\nWe address the choice of the pair of values for the parameters of o ur model,\nnamely the strength of selection \u03b2and the probability of reasoning error \u03b5.\nIn order to retrieve reasonable values, we \ufb01tted our model to two di\ufb00erent\nexperimental references already mentioned in the Results: the se minal study\nby McKelvey and Palfrey [2] and the more recent work by Kawagoe a nd Tak-\nizawa [22]. Both references provide a benchmark for the behaviour al pro\ufb01le\nin the ICG with L= 6 depicted in Figure 1. The main di\ufb00erence between\nthese studies relies on the fact that the latter behavioural exper iment is a\none-shot interaction, while the former consists of ten iterations w ith random\npairing (in this case, we exclusively refer to the frequencies associa ted with\nthe \ufb01rst round, to eliminate potential learning e\ufb00ects). Cultural d i\ufb00erences\nmay also be at play [67, 68, 69, 70], as the experiments in Refs. [2] an d [22]\nwere conducted in American and Japanese universities, respective ly.\nThesedi\ufb00erencesarere\ufb02ectedintheresultsofthe\ufb01ttingshownin Figure 5.\nBy minimizing the Jensen-Shannon divergence between our model\u2019s pr edic-\ntion of the terminal node of the game and the two experimental ref erences,\n29\n\n--- Page 30 ---\nwe obtain rather di\ufb00erent results. When using the data from Ref. [2 2] (Panel\nA), the best \ufb01t is located where the strength of selection and the co gnitive\nnoise take values \u03b2\u2217= 0.063 and \u03b5\u2217= 0.186, respectively. In this case,\nthe relatively high value of \u03b5implies that the three di\ufb00erent reasoning ker-\nnels, and particularly the positively biased one, are necessary to ex plain the\nexperimental results.\nIn contrast, when using the data from Ref. [2] (Panel B), the best \ufb01tting\nis given by lower values, \u03b2\u2217= 0.032 and \u03b5\u2217= 0.062 respectively. This im-\nplies that, in this case, the most relevant factors to explain the dat a are the\nstochastic e\ufb00ects of the imitation process (represented by the lo w strength of\nselection), aswell asthereasoningcapacityofeachindividual (rep resented by\nthelevelk). However, thelowvalueofcognitivenoiseleadstomarginaldi\ufb00er-\nences in reasoning types and consequently to almost deterministic s trategies.\nDespite the highly mitigated di\ufb00erences between reasoning kernels, we have\nseen in Figure 2 (Panel C) that it is yet preferable to develop positively\nbiased reasoning, especially under the e\ufb00ect of stronger selection .\nAlthough general trust , intended as an expectation of strangers\u2019 goodwill,\nhasbeensuggested tobemoreprevalent inwestern cultures (par ticularlyAn-\nglophone), Japanese culture has been associated with assurance-based trust ,\nwhich does not require a belief in the benevolence of the other perso n be-\ncause it is rather based on the mutual knowledge of the incentive st ructure\nsurrounding the relationship [67]. This general \ufb01nding is con\ufb01rmed b y cross-\ncultural studies involving the Centipede Game [69, 70], where Japane se par-\nticipants systematically ended the game at nodes later than Wester n partici-\npants. Our results appear to corroborate these previous \ufb01nding s, as approx-\nimately 51% of the population in our model adopts the strategy asso ciated\nwithonestepofpositively biased reasoningwhen\ufb01ttedontheJapan esedata,\nwhile the distribution of strategies is more heterogeneous when the model is\n\ufb01tted on the American data, with one step of positively biased reaso ning\nbeing nevertheless the most frequent strategy (approximately 1 8%).\nB Derivation of the reasoning strategies\nHere we report the mathematical derivation of the strategies of o ur model.\nStarting from Equation 2, it is useful to encode the noisy best resp onses,\nNBRi(\u00b7), into two role-dependent matrices, M1(\u03b5) andM2(\u03b5), which depend\non the intensity of the cognitive noise \u03b5and contain the probabilities of\n30\n\n--- Page 31 ---\n10\u22123\n10\u22122\n10\u22121\n100\n\u03b2  (i(te(\u2212it2 of \u2212electio( )0.000.050.100.150.200.250.30\u03b5  (reasoning error probability)\u03b2*\n= 0.063, \u03b5*\n= 0.186ICG, L = 6 - Reference: Kawagoe & Takizawa, 2012\n10\u22123\n10\u22122\n10\u22121\n100\n\u03b2  (i(te(\u2212it2 of \u2212electio( )0.000.050.100.150.200.250.30\u03b5  (reasoning error probability)\u03b2*\n= 0.032, \u03b5*\n= 0.062ICG, L = 6 - Reference: McKelvey & Palfrey , 1992\n0 1 2 3 4 5 6\nnode0.00.10.20.30.40.50.6frequency\u03b2*\n= 0.063, \u03b5*\n= 0.186\nmodel prediction\nreference\nKawagoe & T akizawa, 20 12\n0 1 2 3 4 5 6\nnode0.00.10.20.30.40.50.6frequency\u03b2*\n= 0.032 , \u03b5*\n= 0.062\nmodel prediction\nreference\nMcKelvey & P alfrey , 1992\u22121.3 \u22121.1 \u22120.9 \u22120.7 \u22120.5 \u22120.3 \u22120.1 \u22120.84 \u22120.72 \u22120.60 \u22120.48 \u22120.36 \u22120.24 \u22120.12A C\nB D\nFigure 5: Fitting with experimental references. We \ufb01t our model to the\nexperimental data related to the ICG with L= 6 from Refs. [22] and [2]\n(panelsA,BandC,D, respectively). Panels A,Cshow the Jensen-Shannon\ndivergence between our model\u2019s prediction and each experimental r eference\n(in logarithmic scale) as a function of the strength of selection \u03b2and the\nprobability of reasoning errors \u03b5. In the case of Ref. [22], the minimum\ndistance (0.06) is achieved when \u03b2\u2217= 0.063 and\u03b5\u2217= 0.186. When using the\ndata from Ref. [2], the minimum distance (0.16) is reached when \u03b2\u2217= 0.032\nand\u03b5\u2217= 0.062. Panels B,Dportray the comparison between the optimal\n\ufb01tting and the experimental reference in both cases. The populat ion size is\n\ufb01xed to 100 individuals.\n31\n\n--- Page 32 ---\nchoosing a certain response (column) given the belief about the act ion of the\nco-player (row):\n[Mi(\u03b5)]t\u2212i,ti=P(NBRi(t\u2212i) =ti|T\u2212i(k\u22121) =t\u2212i).\nThen, we can rewrite Equation 2 in the following compact form:\n\u03c3i(k) =\u03c3\u2212i(k\u22121)\u00b7Mi(\u03b5)\nwithi\u2208 {1,2}, andk >0. Finally, if we concatenate the two mixed strategy\nvectors\u03c31(k) and\u03c32(k) into one vector \u03c3(k) = [\u03c31(k), \u03c32(k)] and de\ufb01ne a\nsingle (L+2)\u00d7(L+2) block matrix, M(\u03b5), such that\nM(\u03b5) =/bracketleftbigg0M2(\u03b5)\nM1(\u03b5)0/bracketrightbigg\nwe obtain the following simple analytical formula encompassing the str ategy\nof a player covering both roles with equal probability:\n\u03c3(k) =\u03c3(0)\u00b7M(\u03b5)k.\nAsmentionedintheMethods, weconsiderthreereasoningkernels, namely\nMU(\u03b5),MB\u2212(\u03b5), andMB+(\u03b5) for unbiased, negatively and positively biased\n32\n\n--- Page 33 ---\nreasoning, respectively. Here, wereportthethreematricesfor thecaseL= 6:\nMU(\u03b5) =\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f00 0 0 0 1 /4 1/4 1/4 1/4\n0 0 0 0 1 \u2212\u03b5 \u03b5/3\u03b5/3\u03b5/3\n0 0 0 0 \u03b5/3 1\u2212\u03b5 \u03b5/3\u03b5/3\n0 0 0 0 \u03b5/3\u03b5/3 1\u2212\u03b5 \u03b5/3\n1\u2212\u03b5 \u03b5/3\u03b5/3\u03b5/3 0 0 0 0\n\u03b5/3 1\u2212\u03b5 \u03b5/3\u03b5/3 0 0 0 0\n\u03b5/3\u03b5/3 1\u2212\u03b5 \u03b5/3 0 0 0 0\n\u03b5/3\u03b5/3\u03b5/3 1\u2212\u03b50 0 0 0\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb,\nMB\u2212(\u03b5) =\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f00 0 0 0 1 /4 1/4 1/4 1/4\n0 0 0 0 1 0 0 0\n0 0 0 0 \u03b51\u2212\u03b50 0\n0 0 0 0 \u03b5/2\u03b5/2 1\u2212\u03b50\n1 0 0 0 0 0 0 0\n\u03b51\u2212\u03b50 0 0 0 0 0\n\u03b5/2\u03b5/2 1\u2212\u03b50 0 0 0 0\n\u03b5/3\u03b5/3\u03b5/3 1\u2212\u03b50 0 0 0\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb,\nMB+(\u03b5) =\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f00 0 0 0 1 /4 1/4 1/4 1/4\n0 0 0 0 1 \u2212\u03b5 \u03b5/3\u03b5/3\u03b5/3\n0 0 0 0 0 1 \u2212\u03b5 \u03b5/2\u03b5/2\n0 0 0 0 0 0 1 \u2212\u03b5 \u03b5\n1\u2212\u03b5 \u03b5/3\u03b5/3\u03b5/3 0 0 0 0\n0 1\u2212\u03b5 \u03b5/2\u03b5/2 0 0 0 0\n0 0 1 \u2212\u03b5 \u03b5 0 0 0 0\n0 0 0 1 0 0 0 0\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb.\nNote that if Player 2 believes that Player 1 will stop the game at the \ufb01r st\nnode (T= 0), then Player 2 is indi\ufb00erent about the action to take, i.e., there\nis no best response. This explains the uniform probability distribution over\nthe actions of Player 2 in the \ufb01rst row of each matrix.\n33",
  "project_dir": "artifacts/projects/enhanced_cs.MA_2508.20799v1_Evolution_favours_positively_biased_reasoning_in_s",
  "communication_dir": "artifacts/projects/enhanced_cs.MA_2508.20799v1_Evolution_favours_positively_biased_reasoning_in_s/.agent_comm",
  "assigned_at": "2025-08-30T20:48:57.308582",
  "status": "assigned"
}